<?xml version="1.0"?>
<html xmlns="http://www.w3.org/1999/xhtml">

  <head>
    <title>VOI-aware MCTS</title>
    <!-- metadata -->
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="generator" content="PSS" />
    <meta name="version" content="PSS 0.0" />
    <meta name="author" content="David Tolpin" />
    <meta name="company" content="Offtopia" />
    <!-- style links -->
    <link rel="stylesheet" href="style/poster.css" type="text/css" id="posterStyle"/>
    <link rel="stylesheet" href="style/view.css" type="text/css" media="projection" id="viewStyle" />
    <link rel="stylesheet" href="style/print.css" type="text/css" media="print" id="printStyle" />
    <link rel="stylesheet" href="style/read.css" type="text/css" media="screen" id="readStyle" />

    <!-- script links -->
    <script src="./mathjax/MathJax.js" type="text/javascript">
      MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX","output/HTML-CSS"],
      tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]},
      noImageFonts: true
      });
    </script>
    <script src="script/poster.js" type="text/javascript"></script>
  </head>
  <body>
    <div class="author">David&nbsp;Tolpin,&nbsp;Solomon&nbsp;Eyal&nbsp;Shimony<br/>Ben Gurion University of the Negev,<br/>Beer Sheva, Israel
    </div>
    <h1>VOI-aware MCTS<br/><span style="font-size: 80%; line-height: 0.5">ECAI 2012</span></h1>

    <div class="tosafot">
      <div class="zoomable region">
        <h2><span>Multi-armed Bandits</span></h2>
        <img src="bandit.png" style="width: 40%; float: right"/>
        <ul>
          <li>&#x2022;&#x2007;A set of $K$ arms.</li>
          <li>&#x2022;&#x2007;Each arm can be pulled multiple times.</li>
          <li>&#x2022;&#x2007;When the $i$th arm is pulled, a random reward $X_i$ is encountered.</li>
        </ul>
        <h4><span>Regret minimization:</span></h4>
        <ul>
          <li>&#x25e6;&#x2007;<em>Simple regret (<b>SR</b>):</em> the reward of the last pull only is collected.</li>
          <li>&#x25e6;&#x2007;<em>Cumulative regret (<b>CR</b>):</em>  all rewards are accumulated.</li>
        </ul>
      </div>
      <div class="zoomable region">
        <h2 style="clear: right"><span>UCB and UCT</span></h2>
        <ul>
          <li>&#x2022;&#x2007;<b>UCB</b>$(c)$ pulls arm $i$ that maximizes 
          upper confidence bound $b_i$ on the reward:
          $b_i=\overline X_i+\sqrt {\frac {c \log (n)} {n_i}}$
</li>
          <li>&#x2022;&#x2007;UCB is nearly optimal in minimizing the <i>cumulative regret</i>.</li>

          <li>&#x2022;&#x2007;<b>UCT</b> extends UCB to MCTS by invoking UCB at every node of a rollout.</li>
        </ul>
      </div>
      <div class="zoomable region">
        <h2><span>Metareasoning</span></h2>
        <ul>
          <li>&#x2022;&#x2007;A problem-solving agent can perform <i>base-level</i> actions from a known
          set $\{A_i\}$ .</li>
          <li>&#x2022;&#x2007;Before committing to an action, the agent may perform a sequence of
          <i>meta-level</i> deliberation actions from a set $\{S_j\}$ .</li>
          <li>&#x2022;&#x2007;At any given time there is a base-level action $A_\alpha$ that maximizes
          the agent's <i>expected utility.</i></li>
          <li>&#x2022;&#x2007;The <em>value of information</em> $VOI_j$
          is the expected difference between the expected utilities of the new
          and the old selected base-level action <em>after meta-level
          action $S_j$ is taken.</em></li>
          <li>&#x2022;&#x2007;The agent selects a meta-level action that <em>maximizes the VOI,</em> or $A_\alpha$ if no meta-level action has positive VOI.</li>
        </ul>
      </div>
      <div class="zoomable region derecharetz" style="margin-top: 2em">
        <h2><span>Acknowledgments</span></h2>
        <ul>
          <li>&#x2022;&#x2007;Israel Science Foundation grant 305/09</li>
          <li>&#x2022;&#x2007;Lynne and William Frankel Center for Computer Sciences</li>
          <li>&#x2022;&#x2007;Paul Ivanier Center for Robotics Research and Production Management</li>
        </ul>

      </div>
    </div>

    
    <div class="rashi">
       <div class="zoomable region gmara">
        <h2><span>Experiments</span></h2>
        <ul>
          <li>&#x2022;&#x2007;<em>VOI-based sampling</em> is better than <em>UCB1</em> for <strong>simple regret</strong> in Bandits.</li>
          <li>&#x2022;&#x2007;<em>The hybrid scheme</em> outperforms <em>UCT</em>.</li>
        </ul>
        <h3><span>Multi-armed Bandits</span></h3>
         <h4><span>25 arms, 10000 trials</span></h4>
        <p>
          <object class="results" data="flat.svg"></object>
        </p>        
        <h3><span>Computer Go</span></h3>
        <p style="text-align: center">
          <object class="results" data="go-board.svg" style="width: 80%"></object>
        </p>        
        <h3><span>Tuning the Sample Cost</span></h3>
        <p>
          <object class="results" data="uctvoi.svg"></object>
        </p>
        <dl>
          <dt>Best results for sample cost $\approx 10^{-6}$:</dt>
          <dd>winning rate of <em>64%</em> for 10000 samples per ply.</dd>
        </dl>
        <h3><span>Winning rate vs. number of samples</span></h3>
        <h4>Sample cost fixed at $10^{-6}$:</h4>
        <p>
          <object class="results" data="voi-wins.svg"></object>
        </p>
        <p>Best results for <em>intermediate $N_{samples}$</em>:
        <ul>
          <li>&#x2022;&#x2007;When $N_{samples}$ is too low, poor moves are selected.</li>
          <li>&#x2022;&#x2007;When $N_{samples}$ is too high, the VOI of further sampling
  is low.</li>
        </ul>
       </div>
    </div>

    <div class="guf">
      <div class="zoomable region mishna">
        <h2><span>Monte-Carlo Sampling in Trees</span></h2>
        <ul>
          <li>&#x2022;&#x2007;MCTS performs multiple <i>rollouts</i> to partially explore the search space.</li>
          <li>&#x2022;&#x2007;At the current root node, the sampling is aimed at finding the <em>first&nbsp;move</em> to perform: minimizing the <em>simple regret</em> is more appropriate at the root node.</li>
          <li>&#x2022;&#x2007;Deeper in the tree, minimizing <em>cumulative regret</em> results in a better estimate of the value of the state.</li>
          <li>&#x2022;&#x2007;An improvement over UCT can be achieved by <strong>combining different sampling&nbsp;schemes</strong> on the first step and during the rest of a rollout.</li>
        </ul>
        <p>
          <object data="mcts-tree.svg" width="100%"></object>
        </p>
      </div>
      <div class="zoomable region halacha">
        <h2><span>Main Results</span></h2>
          <h3><span>Hybrid sampling scheme</span></h3>
          <ol>
            <li>At the <em>root node</em>: sample based on the VOI estimate.</li>
            <li>At <em>non-root nodes</em>: sample using UCT.</li>
          </ol>
        <h3><span>Upper Bounds on VOI</span></h3>
        <p>Upper bounds on intrinsic VOI $\Lambda^b_i$ of testing the $i$th arm N times:</p>
          $$\Lambda_\alpha^b < \frac {N\overline X_\beta^{n_\beta}}{n_\alpha+1}\cdot 2\exp\left(- 1.37(\overline X_\alpha^{n_\alpha}\hspace{-0.5em} - \overline X_\beta^{n_\beta})^2 n_\alpha\right)$$
          $$\Lambda_{i|i\ne\alpha}^b <  \frac {N(1-\overline X_\alpha^{n_\alpha})} {n_i+1}\cdot 2\exp\left(- 1.37(\overline X_\alpha^{n_\alpha}\hspace{-0.5em} - \overline X_i^{n_i})^2 n_i\right)$$
          <h3><span>Sample Redistribution</span></h3>
          <p>MCTS may <strong>re-use rollouts</strong> generated at earlier search states.
          <ol>
            <li><em>Estimate VOI</em> as though the information is discarded.</li>
            <li><em>Stop early</em> if the VOI is below a certain threshold.</li>
            <li><em>Save the unused</em> sample budget for search in future states.</li>
          </ol>
          <p>The <strong>cost of a sample</strong>  is the VOI of increasing a <strong>future budget</strong> by one sample.</p>
        </div>
    </div>

    <div style="clear: both" />

    <div class="zoomable region musar">
      <h2><span>Contributions</span></h2>
      <ul>
       <li>&#x2022;&#x2007;<em>Hybrid</em> MCTS sampling scheme.</li>
       <li>&#x2022;&#x2007;<em>Upper bounds on VOI</em> for <i>simple regret</i> in Multi-armed Bandits.</em></li>
       <li>&#x2022;&#x2007;VOI-based <em>stopping</em> and sample redistribution.</li>
      </ul>
	  <br/>
    </div>

    <div class="zoomable region safek">
      <h2><span>Future Work</span></h2>
      <div class="region barcode">
        <a href="http://www.offtopia.net/ecai-2012-vago-poster/"><img width="100%" src="barcode.png" alt="http://www.offtopia.net/ecai-2012-vago-poster/" /></a>
      </div>
      <ul>
        <li>&#x2022;&#x2007;Better <strong>VOI estimates.</strong></li>
        <li>&#x2022;&#x2007;VOI-based sampling for <strong>non-root nodes.</strong></li>
        <li>&#x2022;&#x2007;Application to <strong>other domains.</strong></li>
      </ul>
	  <br/>
    </div>

    <br style="clear: both" />
    
  </body>
</html>
