% $Id: thesis.tex,v 1.60 2010/04/13 11:12:30 dvd Exp $

\documentclass{article}
\usepackage{algpseudocode}
\usepackage[ruled]{algorithm}
\usepackage{url}
\usepackage{framed}
\usepackage{amsfonts,amsmath,amsthm}
\usepackage{graphicx}
\usepackage{url}
\usepackage{color}

\newcommand {\mean} {\ensuremath {\mathop{\mathrm{mean}}}}
\newcommand {\median} {\ensuremath {\mathop{\mathrm{median}}}}
\newcommand {\N} {\ensuremath {\mathcal{N}}}
\newcommand {\IE} {\ensuremath {\mathbb{E}}}
\newcommand {\cov} {\ensuremath {\mathop{\mathrm{cov}}}}
\newcommand {\BEL} {\ensuremath {\mathop{\mathrm{BEL}}}}

\newtheorem{lemma}{Lemma}

\title{Efficient Sampling Policies for the Walnut Merchant Problem}
\author {David Tolpin \and Solomon Eyal Shimony \\
Department of Computer Science, \\
Ben-Gurion University of the Negev, Beer Sheva, Israel \\
\{tolpin,shimony\}@cs.bgu.ac.il}

\begin{document}

\maketitle

\begin{abstract}

Policies for the Multiarmed Bandit (MB) proved successful for Monte Carlo
tree sampling (MCTS). However, MCTS differs from MB in that only the
final choice, and not all hand pulls, brings a reward. We define the
Walnut Merchant problem (WM) as a model for decision-making in MCTS,
propose efficient sampling policies, theoretirally analyze and
empirically evaluate their performance. The results suggest that
WM policies are better suited for MCTS than MB policies.

\end{abstract}


\section{Introduction}

\section{Background}

\section{Walnut Merchant Problem}

\section{Best Possible Reward in WM}

\section{Efficient Sampling Pollicies}

\section{Empirical Evaluation}

\section*{Acknowledgments}

The research is partially supported by Israel
Science Foundation grant 305/09, by the Lynne and William Frankel
Center for Computer Sciences, and by the Paul Ivanier Center for
Robotics Research and Production Management.

\bibliographystyle{named}
\bibliography{refs}

\end{document}
